NAME:Ota Onyinyechi Onyeani 
APP NUMBER:APP/HND/24/00132
COURSE CODE:AIT 313
COURSE TITLE: ARTIFICIAL INTELLIGENCE 
DATE:4/3/2025
         Question 1:
Compare and constract  Augmented intelligence Vs Artificial intelligence 

AI and Augmented intelligence lies in their purpose and approach, this purposes and approach includes:

I.  AI aims to create autonomous systems that can perform tasks without human intervention, while Augmented AI seeks to enhance human capabilities by providing AI

ii. AI refers to the development of computer systems or software that can perform tasks that typically require human intelligence. These tasks include problem solving, learning from experience, understanding natural language, recognizing patterns, and making decisions. While 
Augmented AI, sometimes called Intelligence Augmentation (IA), refers to the use of AI technologies to enhance human intelligence and decision making rather than replacing humans.

iii. AI focuses on simulating human intelligence, automating tasks, and enabling data driven decision making, while AR enhances real world experiences by overlaying digital information onto our 
surroundings
      
      
  Question 2:
  
History of AI from 1940 till date

The history of artificial intelligence (AI) began in antiquity, with myths, stories, and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen. The study of logic and formal reasoning from antiquity to the present led directly to the invention of the programmable digital computer in the 1940s, a machine based on abstract mathematical reasoning. This device and the ideas behind it inspired scientists to begin discussing the possibility of building an electronic brain.
  
  The field of AI research was founded at a workshop held on the campus of Dartmouth College in 1956.[1] Attendees of the workshop became the leaders of AI research for decades. Many of them predicted that machines as intelligent as humans would exist within a generation. The U.S. government provided millions of dollars with the hope of making this vision come true.
    
Eventually, it became obvious that researchers had grossly underestimated the difficulty of this feat. In 1974, criticism from James Lighthill and pressure from the U.S. Congress led the U.S. and British Governments to stop funding undirected research into artificial intelligence. Seven years later, a visionary initiative by the Japanese Government and the success of expert systems reinvigorated investment in AI, and by the late 1980s, the industry had grown into a billion-dollar enterprise. However, investors' enthusiasm waned in the 1990s, and the field was criticized in the press and avoided by industry (a period known as an "AI winter"). Nevertheless, research and funding continued to grow under other names.

In the early 2000s, machine learning was applied to a wide range of problems in academia and industry. The success was due to the availability of powerful computer hardware, the collection of immense data sets, and the application of solid mathematical methods. Soon after, deep learning proved to be a breakthrough technology, eclipsing all other methods. The transformer architecture debuted in 2017 and was used to produce impressive generative AI applications, amongst other use cases.

Investment in AI boomed in the 2020s. The recent AI boom, initiated by the development of transformer architecture, led to the rapid scaling and public releases of large language models (LLMs) like ChatGPT. These models exhibit human-like traits of knowledge, attention, and creativity, and have been integrated into various sectors, fueling exponential investment in AI. However, concerns about the potential risks and ethical implications of advanced AI have also emerged, prompting debate about the future of AI and its impact on society.
